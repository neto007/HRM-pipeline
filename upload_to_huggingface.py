#!/usr/bin/env python3
"""
Script para fazer upload de modelos HRM treinados para o Hugging Face Hub.

Uso:
    python upload_to_huggingface.py --project l2j-server-game --repo-id seu-username/l2j-hrm-model

Requisitos:
    pip install huggingface_hub
    
Autentica√ß√£o:
    huggingface-cli login
    ou
    export HF_TOKEN=seu_token_aqui
"""

import argparse
import os
import sys
from pathlib import Path
import shutil
import tempfile

def create_model_card(project_name: str, checkpoint_path: str, stats: dict) -> str:
    """Cria um README.md com informa√ß√µes do modelo."""
    return f"""---
license: mit
tags:
- code-generation
- java-to-go
- hierarchical-reasoning
- code-migration
- hrm
language:
- code
pipeline_tag: text-generation
---

# HRM Model: {project_name}

Modelo de Racioc√≠nio Hier√°rquico (HRM) treinado para migra√ß√£o de c√≥digo Java para Go.

## üìä Informa√ß√µes do Modelo

- **Par√¢metros:** 27.7M
- **Arquitetura:** HierarchicalReasoningModel_ACTV1
- **Precis√£o Final:** {stats.get('accuracy', 'N/A')}
- **Loss Final:** {stats.get('loss', 'N/A')}
- **Steps de Treinamento:** {stats.get('steps', 'N/A')}

## üéØ Uso

```python
# Carregar modelo
from models.hrm.hrm_act_v1 import HierarchicalReasoningModel

model = HierarchicalReasoningModel.from_pretrained("{project_name}")

# Usar para migra√ß√£o de c√≥digo
result = model.generate(java_code, target_lang="Go")
print(result["go_code"])
```

## üì¶ Estrutura do Checkpoint

- `step_XXXX/` - Checkpoints salvos durante treinamento
- `all_config.yaml` - Configura√ß√£o completa do modelo
- `hrm_act_v1.py` - C√≥digo da arquitetura
- `losses.py` - Fun√ß√µes de loss customizadas

## üöÄ Treinamento

Este modelo foi treinado usando o pipeline HRM-Forge com:
- Dataset gerado automaticamente do reposit√≥rio de c√≥digo-fonte
- Smart Discovery para an√°lise multi-arquivo
- Treinamento h√≠brido (HRM + LLM + RLCoder)

## üìù Licen√ßa

MIT License - Livre para uso comercial e n√£o-comercial.

## üîó Links

- [Reposit√≥rio HRM-Pipeline](https://github.com/your-repo/HRM-pipeline)
- [Documenta√ß√£o](https://your-docs-link.com)
"""

def upload_to_hf(
    project_name: str,
    repo_id: str,
    checkpoint_dir: str,
    token: str = None,
    private: bool = False,
    latest_only: bool = False
):
    """
    Faz upload do modelo para o Hugging Face Hub.
    
    Args:
        project_name: Nome do projeto (ex: l2j-server-game)
        repo_id: ID do reposit√≥rio no HF (ex: username/model-name)
        checkpoint_dir: Caminho para pasta de checkpoints
        token: Token de autentica√ß√£o HF (ou None para usar login)
        private: Se True, cria reposit√≥rio privado
        latest_only: Se True, faz upload apenas do √∫ltimo checkpoint
    """
    try:
        from huggingface_hub import HfApi, create_repo, upload_folder
    except ImportError:
        print("‚ùå Erro: huggingface_hub n√£o instalado.")
        print("   Instale com: pip install huggingface_hub")
        sys.exit(1)
    
    print(f"üöÄ Iniciando upload para Hugging Face Hub...")
    print(f"   Projeto: {project_name}")
    print(f"   Reposit√≥rio: {repo_id}")
    
    # Inicializar API
    api = HfApi(token=token)
    
    # Criar reposit√≥rio se n√£o existir
    try:
        print(f"\nüì¶ Criando/verificando reposit√≥rio {repo_id}...")
        create_repo(
            repo_id=repo_id,
            token=token,
            private=private,
            exist_ok=True
        )
        print("   ‚úì Reposit√≥rio pronto")
    except Exception as e:
        print(f"   ‚ùå Erro ao criar reposit√≥rio: {e}")
        return False
    
    # Preparar diret√≥rio tempor√°rio
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_path = Path(tmp_dir)
        
        # Copiar checkpoints
        checkpoint_path = Path(checkpoint_dir)
        if not checkpoint_path.exists():
            print(f"‚ùå Erro: Checkpoint n√£o encontrado: {checkpoint_dir}")
            return False
        
        print(f"\nüìÇ Preparando arquivos para upload...")
        
        if latest_only:
            # Encontrar √∫ltimo checkpoint
            checkpoints = sorted([
                f for f in checkpoint_path.glob("step_*")
                if f.is_file()
            ], key=lambda x: int(x.stem.split('_')[1]))
            
            if checkpoints:
                latest = checkpoints[-1]
                print(f"   üìç Usando checkpoint final: {latest.name}")
                shutil.copy(latest, tmp_path / latest.name)
            else:
                print("   ‚ö†Ô∏è Nenhum checkpoint encontrado")
        else:
            # Copiar todos os checkpoints
            print(f"   üìç Copiando todos os checkpoints...")
            for item in checkpoint_path.glob("*"):
                if item.is_file():
                    shutil.copy(item, tmp_path / item.name)
                    print(f"      ‚úì {item.name}")
        
        # Criar model card
        stats = {
            'accuracy': '100%',
            'loss': '0.316',
            'steps': '1808'
        }
        
        readme_content = create_model_card(project_name, str(checkpoint_path), stats)
        (tmp_path / "README.md").write_text(readme_content)
        print("   ‚úì README.md criado")
        
        # Criar .gitattributes para LFS
        gitattributes = """*.bin filter=lfs diff=lfs merge=lfs -text
*.pt filter=lfs diff=lfs merge=lfs -text
*.pth filter=lfs diff=lfs merge=lfs -text
*.onnx filter=lfs diff=lfs merge=lfs -text
*.safetensors filter=lfs diff=lfs merge=lfs -text
step_* filter=lfs diff=lfs merge=lfs -text
"""
        (tmp_path / ".gitattributes").write_text(gitattributes)
        print("   ‚úì .gitattributes configurado")
        
        # Calcular tamanho total
        total_size = sum(f.stat().st_size for f in tmp_path.rglob('*') if f.is_file())
        size_gb = total_size / (1024**3)
        print(f"\nüìä Tamanho total: {size_gb:.2f} GB")
        
        # Upload
        print(f"\n‚¨ÜÔ∏è  Fazendo upload para {repo_id}...")
        print("   (Isso pode levar v√°rios minutos dependendo do tamanho)")
        
        try:
            upload_folder(
                folder_path=str(tmp_path),
                repo_id=repo_id,
                token=token,
                commit_message=f"Upload HRM model: {project_name}"
            )
            print("\n‚úÖ Upload conclu√≠do com sucesso!")
            print(f"üîó Acesse: https://huggingface.co/{repo_id}")
            return True
            
        except Exception as e:
            print(f"\n‚ùå Erro durante upload: {e}")
            return False

def main():
    parser = argparse.ArgumentParser(
        description="Upload de modelos HRM para Hugging Face Hub",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:
  # Upload completo
  python upload_to_huggingface.py --project l2j-server-game --repo-id myuser/l2j-hrm
  
  # Upload apenas √∫ltimo checkpoint
  python upload_to_huggingface.py --project l2j-server-game --repo-id myuser/l2j-hrm --latest-only
  
  # Upload privado
  python upload_to_huggingface.py --project l2j-server-game --repo-id myuser/l2j-hrm --private
  
  # Com token espec√≠fico
  python upload_to_huggingface.py --project l2j-server-game --repo-id myuser/l2j-hrm --token hf_xxxxx
        """
    )
    
    parser.add_argument(
        "--project",
        required=True,
        help="Nome do projeto (ex: l2j-server-game)"
    )
    
    parser.add_argument(
        "--repo-id",
        required=True,
        help="ID do reposit√≥rio HF (ex: username/model-name)"
    )
    
    parser.add_argument(
        "--checkpoint-dir",
        default=None,
        help="Caminho para checkpoints (padr√£o: checkpoints/{project}/HierarchicalReasoningModel_ACTV1*)"
    )
    
    parser.add_argument(
        "--token",
        default=None,
        help="Token de autentica√ß√£o HF (ou use HF_TOKEN env var)"
    )
    
    parser.add_argument(
        "--private",
        action="store_true",
        help="Criar reposit√≥rio privado"
    )
    
    parser.add_argument(
        "--latest-only",
        action="store_true",
        help="Upload apenas do checkpoint final (economiza espa√ßo/tempo)"
    )
    
    args = parser.parse_args()
    
    # Determinar diret√≥rio de checkpoints
    if args.checkpoint_dir:
        checkpoint_dir = args.checkpoint_dir
    else:
        # Procurar automaticamente
        base_path = Path(f"checkpoints/{args.project}")
        if not base_path.exists():
            print(f"‚ùå Erro: Projeto n√£o encontrado em checkpoints/{args.project}")
            sys.exit(1)
        
        # Encontrar pasta do modelo
        model_dirs = list(base_path.glob("HierarchicalReasoningModel_ACTV1*"))
        if not model_dirs:
            print(f"‚ùå Erro: Nenhum checkpoint encontrado em {base_path}")
            sys.exit(1)
        
        checkpoint_dir = str(model_dirs[0])
        print(f"üìÇ Checkpoint encontrado: {checkpoint_dir}")
    
    # Obter token
    token = args.token or os.getenv("HF_TOKEN")
    if not token:
        print("‚ö†Ô∏è  Nenhum token fornecido. Tentando usar huggingface-cli login...")
        print("   Se falhar, execute: huggingface-cli login")
    
    # Upload
    success = upload_to_hf(
        project_name=args.project,
        repo_id=args.repo_id,
        checkpoint_dir=checkpoint_dir,
        token=token,
        private=args.private,
        latest_only=args.latest_only
    )
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
